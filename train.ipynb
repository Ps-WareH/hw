{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from unet import UNet  # 假设 UNet 是 unet.py 中定义的一个类\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 如果图像不是PIL图像则需要转换\n",
    "    transforms.Resize((256, 1024)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 将图像转换为torch.Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "])\n",
    "\n",
    "# 掩膜的转换操作，掩膜不需要标准化\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 如果掩膜不是PIL图像则需要转换\n",
    "    transforms.Resize((256, 1024), interpolation=transforms.InterpolationMode.NEAREST),  # 调整大小，使用最近邻插值\n",
    "    transforms.ToTensor()  # 将掩膜转换为torch.Tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset = dataset.KITTIDataset('tinySet/img', 'tinySet/mask', transform=image_transform, mask_transform=mask_transform,device=device)\n",
    "dataloader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "model = UNet(in_ch=3,out_ch=22).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.Size([4, 3, 256, 1024])\n"
     ]
    }
   ],
   "source": [
    "for i, (images, masks) in enumerate(dataloader):\n",
    "     print(masks.type())\n",
    "     print(images.shape)\n",
    "     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.2100603580474854\n",
      "Epoch 2, Loss: 3.0265517234802246\n",
      "Epoch 3, Loss: 2.8276712894439697\n",
      "Epoch 4, Loss: 2.6669654846191406\n",
      "Epoch 5, Loss: 2.5580217838287354\n",
      "Epoch 6, Loss: 2.5067832469940186\n",
      "Epoch 7, Loss: 2.4736194610595703\n",
      "Epoch 8, Loss: 2.4299087524414062\n",
      "Epoch 9, Loss: 2.3780429363250732\n",
      "Epoch 10, Loss: 2.3519949913024902\n"
     ]
    }
   ],
   "source": [
    "def train(model, loader, optimizer, criterion, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for i, (images, masks) in enumerate(loader):\n",
    "\n",
    "            masks = masks.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            masks = masks.squeeze(1) \n",
    "            loss = criterion(outputs, masks)  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "train(model, dataloader, optimizer, criterion, 10)\n",
    "# 保存整个模型\n",
    "torch.save(model, 'model_complete.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13 13 13 ... 13 13 13]\n",
      " [10 13 13 ... 10 14 13]\n",
      " [10 10 10 ... 10 10 13]\n",
      " ...\n",
      " [10 10 10 ... 10 10 13]\n",
      " [10 10 10 ... 10 10 14]\n",
      " [10 10 10 ... 10 10 18]]\n",
      "[[13 13 13 ... 13 13 13]\n",
      " [13 13 13 ... 13 13 13]\n",
      " [10 10 10 ... 10 18 13]\n",
      " ...\n",
      " [10 10 10 ... 10 25 13]\n",
      " [10 10 10 ... 10 13 18]\n",
      " [10 10 10 ... 28 13 13]]\n",
      "[[18 10 10 ... 10 10 13]\n",
      " [10 29 10 ... 10 10 10]\n",
      " [10 10 10 ... 10 10 10]\n",
      " ...\n",
      " [10 10 10 ... 10 13 13]\n",
      " [10 10 10 ... 10 13 13]\n",
      " [10 10 10 ... 10 13 13]]\n",
      "[[13 13 29 ... 13 10 10]\n",
      " [10 10 10 ... 10 10 10]\n",
      " [10 10 10 ... 13 10 13]\n",
      " ...\n",
      " [10 10 10 ... 10 25 13]\n",
      " [10 10 10 ... 10 13 18]\n",
      " [10 10 10 ... 28 13 13]]\n",
      "[[13 13 10 ... 13 13 13]\n",
      " [13 13 13 ... 13 13 13]\n",
      " [10 10 10 ... 10 18 13]\n",
      " ...\n",
      " [10 10 10 ... 10 25 13]\n",
      " [10 13 18 ... 10 13 13]\n",
      " [10 10 10 ... 28 13 13]]\n",
      "[[13 13 13 ... 13 13 13]\n",
      " [28 10 10 ... 10 22 13]\n",
      " [28 10 10 ... 25 13 13]\n",
      " ...\n",
      " [10 10 25 ... 10 10 10]\n",
      " [10 10 10 ... 10 10 10]\n",
      " [10 10 10 ... 28 10 10]]\n",
      "[[18 10 10 ... 10 13 13]\n",
      " [10 29 10 ... 13 13 13]\n",
      " [10 10 10 ... 25 13 13]\n",
      " ...\n",
      " [10 10 25 ... 10 13 13]\n",
      " [10 10 10 ... 10 13 13]\n",
      " [10 10 10 ... 10 13 13]]\n",
      "[[13 13 13 ... 13 13 13]\n",
      " [13 13 13 ... 10 22 13]\n",
      " [10 10 13 ... 10 10 13]\n",
      " ...\n",
      " [28 10 10 ... 25 25 13]\n",
      " [15 10 10 ... 10 13 13]\n",
      " [10 10 10 ... 28 13 18]]\n",
      "[[13 13 10 ... 13 13 29]\n",
      " [13 13 10 ... 10 10 29]\n",
      " [10 10 10 ... 10 10 10]\n",
      " ...\n",
      " [10 10 25 ... 10 25 13]\n",
      " [10 10 10 ... 10 13 18]\n",
      " [10 10 10 ... 28 13 13]]\n",
      "[[13 13 13 ... 22 13 13]\n",
      " [13 13 13 ... 10 22 13]\n",
      " [10 10 10 ... 10 28 13]\n",
      " ...\n",
      " [10 10 10 ... 10 13 13]\n",
      " [10 10 10 ... 10 13 13]\n",
      " [10 13 10 ... 10 13 13]]\n",
      "[[13 13 13 ... 29 10 10]\n",
      " [13 13 10 ... 10 10 29]\n",
      " [10 10 10 ... 10 10 13]\n",
      " ...\n",
      " [10 10 10 ... 10 25 13]\n",
      " [10 10 10 ... 10 13 13]\n",
      " [10 10 10 ... 28 13 13]]\n",
      "[[18 10 10 ... 10 28 13]\n",
      " [10 13 10 ... 22 22 13]\n",
      " [10 10 10 ... 10 13 13]\n",
      " ...\n",
      " [10 10 10 ... 10 13 13]\n",
      " [13 13 10 ... 10 13 13]\n",
      " [10 13 10 ... 10 13 13]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "\n",
    "def predict_and_save(model, loader, save_dir):\n",
    "    model.eval()\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    with torch.no_grad():\n",
    "        for images, filenames in loader:\n",
    "            # 假设你的模型和数据都在同一设备上\n",
    "            outputs = model(images)\n",
    "            predicted_masks = torch.argmax(outputs, dim=1)\n",
    "            for i, filename in enumerate(filenames):\n",
    "                # 将每张预测的掩膜转换为 numpy 数组\n",
    "                mask = predicted_masks[i].cpu().numpy().astype(np.uint8)\n",
    "                # mask+=10\n",
    "                print(mask)\n",
    "\n",
    "                # 将 mask 转换为 PIL 图像并保存\n",
    "                pil_image = Image.fromarray(mask)\n",
    "                save_path = os.path.join(save_dir, os.path.splitext(filename)[0] + '.png')\n",
    "                pil_image.save(save_path)\n",
    "\n",
    "# 初始化和调用你的模型和数据加载器\n",
    "test_dataset = dataset.TestDataset('tinySet/img', transform=image_transform,device=device)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "save_masks_dir = 'predicted_masks'\n",
    "predict_and_save(model, test_loader, save_masks_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
